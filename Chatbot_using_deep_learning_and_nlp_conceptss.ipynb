{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ceefeb-2683-4b0b-9813-cdccbe89a21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65e787d4-efc1-46b9-afd1-ea3a1875f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.2 MB 1.3 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.1/1.2 MB 1.8 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 0.2/1.2 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.3/1.2 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.5/1.2 MB 2.4 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 0.6/1.2 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.6/1.2 MB 2.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 0.8/1.2 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.0/1.2 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.1/1.2 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Obtaining dependency information for pillow!=8.3.*,>=5.3.0 from https://files.pythonhosted.org/packages/66/d4/054e491f0880bf0119ee79cdc03264e01d5732e06c454da8c69b83a7c8f2/Pillow-10.0.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading Pillow-10.0.0-cp311-cp311-win_amd64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\raghav\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading Pillow-10.0.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.5/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.9/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.1/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.5/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.0/2.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.2/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-10.0.0 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03be9bd3-f80f-4552-84a4-1b9f82cee58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a496b2a-7653-480b-be25-bce50df9ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 0. 0. 0.]\n",
      "How are you doing?\n",
      "['How', 'are', 'you', 'doing', '?']\n",
      "['organ', 'organ', 'organ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Raghav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "\n",
    "def bag_of_words(tokenized_sentence, all_words):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
    "    bag =   [  0,   1,       0,    1,    0,     0,        0]\n",
    "    \"\"\"\n",
    "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
    "    bag = np.zeros(len(all_words),dtype = np.float32)\n",
    "    for index, w in enumerate(all_words):\n",
    "        if w in tokenized_sentence:\n",
    "            bag[index] = 1.0\n",
    "    return bag\n",
    "\n",
    "sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
    "bag = bag_of_words(sentence,words)\n",
    "print(bag)\n",
    "            \n",
    "\n",
    "\n",
    "#use of tokenization\n",
    "a = \"How are you doing?\"\n",
    "print(a)\n",
    "a = tokenize(a)\n",
    "print(a)\n",
    "\n",
    "#use of stemming\n",
    "words = [\"Organize\", \"organizes\", \"Organizing\"]\n",
    "stemmed_words = [stem(w) for w in words]\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b26700-4d39-47f2-9fbd-1bc695e91e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33335171-5ed6-4044-8636-0c665862d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a272aa-36ec-4e26-9f0e-ffaacafa4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('h.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0977dd76-35b7-4a79-a8d1-4da663acf375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Hello,I want to ask some questions'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there,how can I help?', \"Hello sir/ma'am,Welcome!\", \"Hey,I'm mike, What can I do for you? \"]}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye', \"You're great,see you soon\", 'Thank you,great help'], 'responses': ['See you later,thanks for visiting', 'Have a nice day', 'Bye! Come back again soon', 'Pleasure to solve your queries,come back again soon', 'Great to interact with you,Goodbye']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kind of items are there?', 'What do you sell?', 'What are the items do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea', 'We have different types of coffee and tea']}, {'tag': 'types', 'patterns': ['What type of coffe? Hot or cold'], 'responses': ['We sell both types of coffee,But cold one is our speciality because we have different varities available']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Do you accept UPI?', 'Can I pay with paypal?', 'Are you cash only?'], 'responses': ['We accept VISA,UPI,Mastercard and Paypal', 'We accept most major UPI, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 30 minutes', 'Shipping takes 30 minutes']}]}\n"
     ]
    }
   ],
   "source": [
    "with open('h.json', 'r') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "print(intents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f937a77-cba7-4232-9f27-23b9b130feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'re\", \"'s\", 'a', 'accept', 'anyon', 'are', 'ask', 'bye', 'can', 'card', 'cash', 'coff', 'cold', 'credit', 'day', 'deliveri', 'do', 'doe', 'get', 'good', 'goodby', 'great', 'have', 'hello', 'help', 'hey', 'hi', 'hot', 'how', 'i', 'is', 'item', 'kind', 'later', 'long', 'lot', 'mastercard', 'my', 'of', 'onli', 'or', 'pay', 'paypal', 'question', 'see', 'sell', 'ship', 'some', 'soon', 'take', 'thank', 'that', 'the', 'there', 'to', 'type', 'upi', 'want', 'what', 'when', 'which', 'with', 'you']\n",
      "['delivery', 'goodbye', 'greeting', 'items', 'payments', 'thanks', 'types']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    #add to tags list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize each word in the sentence\n",
    "        w = tokenize(pattern)\n",
    "        #add to our words list\n",
    "        all_words.extend(w)\n",
    "        #add to xy pair\n",
    "        xy.append((w,tag))\n",
    "\n",
    "ignore_words =  ['?','!','.',',']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "all_words = sorted(set(all_words))\n",
    "print(all_words)\n",
    "tags = sorted(set(tags))\n",
    "print(tags)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828b2944-6adf-499d-b923-44a805c1dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for(pattern_sentence,tag) in xy:\n",
    "    bag = bag_of_words(pattern_sentence,all_words)\n",
    "    X_train.append(bag)\n",
    "\n",
    "    label = tags.index(tag)\n",
    "    Y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef18e66d-a774-46a0-bc2d-af48d425a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_classes):  #feed forward neural network\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size,num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        #after l3 no activation function and no softmax because we are going to apply crossentropyloss\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a5a205-c513-48a1-8814-0c74ee06dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 63\n",
      "7 ['delivery', 'goodbye', 'greeting', 'items', 'payments', 'thanks', 'types']\n"
     ]
    }
   ],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = Y_train\n",
    "\n",
    "    #dataset(index)\n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    #Hyperparameters\n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, len(all_words))\n",
    "print(output_size,tags)\n",
    "      \n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size = batch_size, shuffle = True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fc6548-7074-4a2c-8b60-68017ff78171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 1.0105\n",
      "Epoch [200/1000], Loss: 0.1306\n",
      "Epoch [300/1000], Loss: 0.0169\n",
      "Epoch [400/1000], Loss: 0.0130\n",
      "Epoch [500/1000], Loss: 0.0016\n",
      "Epoch [600/1000], Loss: 0.0013\n",
      "Epoch [700/1000], Loss: 0.0022\n",
      "Epoch [800/1000], Loss: 0.0007\n",
      "Epoch [900/1000], Loss: 0.0009\n",
      "Epoch [1000/1000], Loss: 0.0006\n",
      "final loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuralNet(input_size,hidden_size,output_size).to(device)\n",
    "\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for(words,labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.long()\n",
    "\n",
    "        #forward\n",
    "        outputs = model(words)\n",
    "        #if y would be one-hot,we must apply\n",
    "        #labels = torch.max(labels,1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if(epoch+1)%100 ==0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c2aff98-c74b-464f-8f5e-31232a2df51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"all_words\": all_words,\n",
    "    \"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data,FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83375477-99a4-4ea6-9afc-ec825ee51d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training part completed..........chat.py started\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('h.json','r') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data[\"all_words\"]\n",
    "tags = data[\"tags\"]\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size,hidden_size,output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Sam\"\n",
    "def get_response(msg):\n",
    "    sentence = tokenize(msg)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                return random.choice(intent['responses'])\n",
    "    \n",
    "    return \"I do not understand...\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a273b82d-0711-4c9b-96eb-976ad216637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as Tk\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcb772ee-c749-4311-a142-43cd626a4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_GRAY = \"#F0F8FF\"\n",
    "BG_COLOR = \"#000000\"\n",
    "TEXT_COLOR = \"#EAECEE\"\n",
    "\n",
    "FONT = \"Helvetica 14\"\n",
    "FONT_BOLD = \"Helvetica 13 bold\"\n",
    "\n",
    "class ChatApplication:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.window = Tk()\n",
    "        self._setup_main_window()\n",
    "        \n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "        \n",
    "    def _setup_main_window(self):\n",
    "        self.window.title(\"Chat\")\n",
    "        self.window.resizable(width=False, height=False)\n",
    "        self.window.configure(width=470, height=550, bg=BG_COLOR)\n",
    "        \n",
    "        # head label\n",
    "        head_label = Label(self.window, bg=BG_COLOR, fg=TEXT_COLOR,\n",
    "                           text=\"Welcome\", font=FONT_BOLD, pady=10)\n",
    "        head_label.place(relwidth=1)\n",
    "        \n",
    "        # tiny divider\n",
    "        line = Label(self.window, width=450, bg=BG_GRAY)\n",
    "        line.place(relwidth=1, rely=0.07, relheight=0.012)\n",
    "        \n",
    "        # text widget\n",
    "        self.text_widget = Text(self.window, width=20, height=2, bg=BG_COLOR, fg=TEXT_COLOR,\n",
    "                                font=FONT, padx=5, pady=5)\n",
    "        self.text_widget.place(relheight=0.745, relwidth=1, rely=0.08)\n",
    "        self.text_widget.configure(cursor=\"arrow\", state=DISABLED)\n",
    "        \n",
    "        # scroll bar\n",
    "        scrollbar = Scrollbar(self.text_widget)\n",
    "        scrollbar.place(relheight=1, relx=0.974)\n",
    "        scrollbar.configure(command=self.text_widget.yview)\n",
    "        \n",
    "        # bottom label\n",
    "        bottom_label = Label(self.window, bg=BG_GRAY, height=80)\n",
    "        bottom_label.place(relwidth=1, rely=0.825)\n",
    "        \n",
    "        # message entry box\n",
    "        self.msg_entry = Entry(bottom_label, bg=\"#2C3E50\", fg=TEXT_COLOR, font=FONT)\n",
    "        self.msg_entry.place(relwidth=0.74, relheight=0.06, rely=0.008, relx=0.011)\n",
    "        self.msg_entry.focus()\n",
    "        self.msg_entry.bind(\"<Return>\", self._on_enter_pressed)\n",
    "        \n",
    "        # send button\n",
    "        send_button = Button(bottom_label, text=\"Send\", font=FONT_BOLD, width=20, bg=BG_GRAY,\n",
    "                             command=lambda: self._on_enter_pressed(None))\n",
    "        send_button.place(relx=0.77, rely=0.008, relheight=0.06, relwidth=0.22)\n",
    "     \n",
    "    def _on_enter_pressed(self, event):\n",
    "        msg = self.msg_entry.get()\n",
    "        self._insert_message(msg, \"You\")\n",
    "        \n",
    "    def _insert_message(self, msg, sender):\n",
    "        if not msg:\n",
    "            return\n",
    "        \n",
    "        self.msg_entry.delete(0, END)\n",
    "        msg1 = f\"{sender}: {msg}\\n\\n\"\n",
    "        self.text_widget.configure(state=NORMAL)\n",
    "        self.text_widget.insert(END, msg1)\n",
    "        self.text_widget.configure(state=DISABLED)\n",
    "        \n",
    "        msg2 = f\"{bot_name}: {get_response(msg)}\\n\\n\"\n",
    "        self.text_widget.configure(state=NORMAL)\n",
    "        self.text_widget.insert(END, msg2)\n",
    "        self.text_widget.configure(state=DISABLED)\n",
    "        \n",
    "        self.text_widget.see(END)\n",
    "             \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    app = ChatApplication()\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
